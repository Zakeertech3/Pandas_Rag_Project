{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b2d60b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Structure Check:\n",
      "Project Root: c:\\Users\\MOHAMMED ZAKEER\\Downloads\\pandas_rag_project\n",
      "Raw Data Path: c:\\Users\\MOHAMMED ZAKEER\\Downloads\\pandas_rag_project\\data\\raw\n",
      "PDF File Path: c:\\Users\\MOHAMMED ZAKEER\\Downloads\\pandas_rag_project\\data\\raw\\mastering_pandas_2025.pdf\n",
      "PDF File Exists: True\n",
      "\n",
      "File Information:\n",
      "File Size: 29.36 MB\n",
      "File Name: mastering_pandas_2025.pdf\n"
     ]
    }
   ],
   "source": [
    "# 01_data_exploration.ipynb - Chunk 1: Setup and PDF Loading\n",
    "\n",
    "# Import required libraries\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up paths\n",
    "PROJECT_ROOT = Path.cwd().parent if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
    "RAW_DATA_PATH = PROJECT_ROOT / 'data' / 'raw'\n",
    "PDF_FILE = RAW_DATA_PATH / 'mastering_pandas_2025.pdf'\n",
    "\n",
    "print(\"Project Structure Check:\")\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"Raw Data Path: {RAW_DATA_PATH}\")\n",
    "print(f\"PDF File Path: {PDF_FILE}\")\n",
    "print(f\"PDF File Exists: {PDF_FILE.exists()}\")\n",
    "\n",
    "# Basic file information\n",
    "if PDF_FILE.exists():\n",
    "    file_size = PDF_FILE.stat().st_size\n",
    "    print(f\"\\nFile Information:\")\n",
    "    print(f\"File Size: {file_size / (1024*1024):.2f} MB\")\n",
    "    print(f\"File Name: {PDF_FILE.name}\")\n",
    "else:\n",
    "    print(\"ERROR: PDF file not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9df74185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PDF Structure:\n",
      "Total Pages: 473\n",
      "\n",
      "PDF Metadata:\n",
      "/Author: Yildiz, Muslum\n",
      "/CreationDate: D:20250520051054+00'00'\n",
      "/Creator: calibre 7.16.0\n",
      "/ModDate: D:20250520051054+00'00'\n",
      "/Producer: calibre 7.16.0\n",
      "/Title: MASTERING PANDAS: A Comprehensive Guide to Data Analysis in Python\n"
     ]
    }
   ],
   "source": [
    "# Load and examine PDF structure\n",
    "try:\n",
    "    with open(PDF_FILE, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        \n",
    "        print(f\"\\nPDF Structure:\")\n",
    "        print(f\"Total Pages: {len(pdf_reader.pages)}\")\n",
    "        \n",
    "        # Check if PDF has metadata\n",
    "        if pdf_reader.metadata:\n",
    "            print(f\"\\nPDF Metadata:\")\n",
    "            for key, value in pdf_reader.metadata.items():\n",
    "                print(f\"{key}: {value}\")\n",
    "        else:\n",
    "            print(\"\\nNo metadata available\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error reading PDF: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32a641a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 0 - Length: 0 characters\n",
      "Page 1 - Length: 121 characters\n",
      "Page 2 - Length: 452 characters\n",
      "Page 50 - Length: 600 characters\n",
      "Page 100 - Length: 644 characters\n",
      "Page 200 - Length: 1401 characters\n",
      "Page 300 - Length: 945 characters\n",
      "Page 472 - Length: 1110 characters\n",
      "\n",
      "=== FIRST PAGE CONTENT (First 500 chars) ===\n",
      "\n",
      "\n",
      "=== SECOND PAGE CONTENT (First 500 chars) ===\n",
      "MASTERING\n",
      "PANDAS\n",
      "A Comprehensive Guide to\n",
      "Data Analysis in P ython\n",
      "By Dr . Muslum Yildiz\n",
      "Copyright © Muslum Y ildiz, 2024\n",
      "\n",
      "=== TABLE OF CONTENTS AREA (Page 2, First 800 chars) ===\n",
      "All rights r eserved.\n",
      "No part of this book may be r eproduced, distributed,\n",
      "or transmitted in any for m or by any means without\n",
      "the prior written per mission of the author, e xcept in\n",
      "the case of brief quotations embodied in r eviews and\n",
      "certain other noncommer cial uses per mitted by\n",
      "copyright law .\n",
      "To my one true love, my wife,\n",
      "and to my two precious\n",
      "daughters—thank you for being\n",
      "my greatest adventure, my\n",
      "constant joy, and my endless\n",
      "inspiration.\n"
     ]
    }
   ],
   "source": [
    "# Extract sample pages to understand document structure\n",
    "def extract_sample_pages(pdf_path, sample_pages=[0, 1, 2, 50, 100, 200, 300, 472]):\n",
    "    \"\"\"Extract text from key pages to understand document structure\"\"\"\n",
    "    samples = {}\n",
    "    \n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        \n",
    "        for page_num in sample_pages:\n",
    "            if page_num < len(pdf_reader.pages):\n",
    "                try:\n",
    "                    text = pdf_reader.pages[page_num].extract_text()\n",
    "                    samples[f\"Page_{page_num}\"] = text\n",
    "                    print(f\"Page {page_num} - Length: {len(text)} characters\")\n",
    "                except:\n",
    "                    samples[f\"Page_{page_num}\"] = \"Extraction failed\"\n",
    "                    print(f\"Page {page_num} - Extraction failed\")\n",
    "    \n",
    "    return samples\n",
    "\n",
    "# Extract samples\n",
    "page_samples = extract_sample_pages(PDF_FILE)\n",
    "\n",
    "# Analyze first few pages for structure\n",
    "print(\"\\n=== FIRST PAGE CONTENT (First 500 chars) ===\")\n",
    "print(page_samples.get('Page_0', 'Not available')[:500])\n",
    "\n",
    "print(\"\\n=== SECOND PAGE CONTENT (First 500 chars) ===\")\n",
    "print(page_samples.get('Page_1', 'Not available')[:500])\n",
    "\n",
    "print(\"\\n=== TABLE OF CONTENTS AREA (Page 2, First 800 chars) ===\")\n",
    "print(page_samples.get('Page_2', 'Not available')[:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17e7289e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PAGE 4 - POTENTIAL TOC/CHAPTER ===\n",
      "Length: 420 chars\n",
      "Content preview:\n",
      "TABLE OF CONTENTS\n",
      "TABLE OF\n",
      "CONTENTS………………………………………………………\n",
      "…………………………4          \n",
      "PREF ACE…………………………………………………………\n",
      "………………………………………….7        \n",
      "INTRODUCTION…………………………………………………\n",
      "………………………………………9          \n",
      "CHAPTER 1 :\n",
      "INTRODUCTION TO\n",
      "PANDAS………………………………………….………………\n",
      "………...11                 \n",
      "CHAPTER 2 :\n",
      "WHY USE PANDAS? IMPOR TANCE IN DATA\n",
      "ANAL YSIS……………………………20  \n",
      "CHAPTER 3 :\n",
      "INSTALLING AND SETTING UP\n",
      "PANDAS………………………….……………………….26\n",
      "---\n",
      "\n",
      "=== PAGE 5 - POTENTIAL TOC/CHAPTER ===\n",
      "Length: 410 chars\n",
      "Content preview:\n",
      "CHAPTER 4 :\n",
      "DATA STRUCTURES IN PANDAS: SERIE S AND\n",
      "DATAFRAMES…………….……30\n",
      "CHAPTER 5 :\n",
      "INDEXING AND SELECTION\n",
      "TECHNIQUES…………………………….…………..……50\n",
      "CHAPTER 6 :\n",
      "PANDAS DATA TYPES AND\n",
      "CONVERSIONS………………………………………………80\n",
      " \n",
      "CHAPTER 7 :\n",
      "HANDLING MISSING DATA IN\n",
      "PANDAS………………………………………..…..……100  \n",
      "CHAPTER 8 :\n",
      "WORKING WITH TEXT\n",
      "DATA………………………………………….……………………\n",
      "…128\n",
      "CHAPTER 9 :\n",
      "PANDAS DATE AND TIME\n",
      "HANDLING………………………………………………….…\n",
      "152\n",
      "---\n",
      "\n",
      "=== PAGE 6 - POTENTIAL TOC/CHAPTER ===\n",
      "Length: 521 chars\n",
      "Content preview:\n",
      "CHAPTER 10 :\n",
      "MASTERING DATA IMPOR T AND EXPOR T IN PANDAS\n",
      "FOR AI……….………163\n",
      "CHAPTER 11 :   \n",
      "ESSENTIAL DATA EXPL ORATION TECHNIQUES IN\n",
      "PANDAS…….……………182    \n",
      "CHAPTER   12 :   \n",
      "DATA CLEANING AND\n",
      "PREPROCESSING………………………………..………………\n",
      "206    CHAPTER 13 :\n",
      "PANDAS AGGREGA TION AND GROUPB Y\n",
      "OPER ATIONS……………..……..……218 CHAPTER 14 :\n",
      "RESHAPING AND PIVOTING\n",
      "DATA………….……………………………………….…….245\n",
      "CHAPTER 15 :\n",
      "MERGING, JOINING, AND CONCA TENA TION IN\n",
      "PANDAS………………………287\n",
      "CHAPTER 16 :\n",
      "FILTERING AND CONDITIONALL Y SELECTING\n",
      "DATA………….……..…………296  \n",
      "---\n",
      "\n",
      "=== PAGE 7 - POTENTIAL TOC/CHAPTER ===\n",
      "Length: 376 chars\n",
      "Content preview:\n",
      "CHAPTER 17 :\n",
      "SORTING AND ORDERING IN\n",
      "PANDAS………………………………….…………….…322\n",
      "CHAPTER 18 :\n",
      "VECTORIZED OPER ATIONS AND\n",
      "BROADCASTING……………………….………..333\n",
      "CHAPTER 19 :\n",
      "WORKING WITH CATEGORICAL\n",
      "DATA……………………..…………………….………341\n",
      "CHAPTER 20 :\n",
      "ADVANCED PANDAS\n",
      "TECHNIQUES……..……………………………………………\n",
      "……354\n",
      "CONCL USION……………………………………………………\n",
      "……………………..…………….365\n",
      "REFERENCES……………………………………………………\n",
      "……………………..…………….368\n",
      "---\n",
      "\n",
      "=== PAGE 9 - POTENTIAL TOC/CHAPTER ===\n",
      "Length: 1565 chars\n",
      "Content preview:\n",
      "and generate insights with the ease and precision that\n",
      "Pandas provides. Whether  you’r e preparing data, conducting\n",
      "advanced analyses, or exploring time-based trends, Pandas\n",
      "becomes your trusted partner in transfor ming data into\n",
      "knowledge.\n",
      "What sets Mastering Pandas  apart is its approach—a blend\n",
      "of practical guidance and modern enhancements powered\n",
      "by AI. This isn’t just a book; it’s a thoughtfully designed\n",
      "learning experience. Through hands-on examples and AI-\n",
      "enhanced visuals, complex concepts become clear and\n",
      "actionable, bridging the gap between theory and real-world\n",
      "application. Each cha\n",
      "---\n",
      "\n",
      "=== PAGE 10 - POTENTIAL TOC/CHAPTER ===\n",
      "Length: 613 chars\n",
      "Content preview:\n",
      "will be more than a library in Python; it will be an essential\n",
      "part of your toolkit for understanding and unlocking the\n",
      "value of data.\n",
      "Let’s step into the futur e of data analysis, wher e Pandas\n",
      "opens doors to endless possibilities. R eady to begin?\n",
      "INTRODUCTION\n",
      "Welcome to Mastering Pandas , your gateway to the\n",
      "transformative world of data analysis in Python. In an age\n",
      "where data shapes the future and drives innovation, the\n",
      "ability to analyze, visualize, and draw insights from data is\n",
      "no longer a specialized skill—it’s essential across every ﬁeld.\n",
      "From business to healthcare, from artiﬁcial in\n",
      "---\n",
      "\n",
      "=== PAGE 12 - POTENTIAL TOC/CHAPTER ===\n",
      "Length: 1114 chars\n",
      "Content preview:\n",
      "With pandas, you’r e not just crunching numbers; you’r e\n",
      "uncovering patter ns, predicting trends, and making data\n",
      "come alive in a way that drives r eal-world impact.\n",
      "What makes Mastering Pandas  unique is that it’s crafted\n",
      "with a modern edge, enhanced by artiﬁcial intelligence to\n",
      "bring data analysis to life. You’ll encounter practical\n",
      "examples and AI-enhanced visuals that demystify even the\n",
      "most intricate aspects of pandas, guiding you through\n",
      "exercises that mirror real-world data challenges. From\n",
      "managing massive datasets to performing detailed\n",
      "statistical analysis, each chapter is designed t\n",
      "---\n",
      "\n",
      "=== PAGE 13 - POTENTIAL TOC/CHAPTER ===\n",
      "Length: 1629 chars\n",
      "Content preview:\n",
      "Introduction to P andas\n",
      "Welcome to the world of Pandas, the powerhouse of data\n",
      "analysis in Python , an open-source library that\n",
      "transforms Python into a complete data science toolkit.\n",
      "Whether you’re dealing with Big Data, high-stakes business\n",
      "analysis, or cutting-edge research, Pandas provides the tools\n",
      "to transform raw data into actionable insights. Created with\n",
      "performance and simplicity in mind, Pandas enables entire\n",
      "data workﬂows—importing, cleaning, transforming,\n",
      "analyzing, and even visualizing—directly within Python.\n",
      "What if you had to navigate through endless seas of data,\n",
      "ﬁlled with sc\n",
      "---\n",
      "\n",
      "=== PAGE 17 - POTENTIAL TOC/CHAPTER ===\n",
      "Length: 1413 chars\n",
      "Content preview:\n",
      "decision-making. For anyone in academia, business, or\n",
      "resear ch, mastering Pandas is a transfor mative step towar d\n",
      "becoming a true e xpert in today’s data-driven world.\n",
      "Pandas is packed with powerful featur es and capabilities\n",
      "that transfor m Python into a data manipulation powerhouse.\n",
      "Imagine having a tool that not only allows you to handle\n",
      "vast dataset s but also makes it easy to ﬁlter, sort, group,\n",
      "and reshape data with just a few lines of code. Pandas’\n",
      "intuitive DataFrame and Series structur es let you handle\n",
      "everything from messy, unstructur ed data to time series\n",
      "analysis and comple x c\n",
      "---\n",
      "\n",
      "=== PAGE 18 - POTENTIAL TOC/CHAPTER ===\n",
      "Length: 1116 chars\n",
      "Content preview:\n",
      "Chapter 2: Why Use Pandas? Importance in Data\n",
      "Analysis  – Exploring Pandas’ unique advantages for\n",
      "data manipulation and how it integrates seamlessly\n",
      "with other data science libraries.\n",
      "Chapter 3: Installing and Setting Up Pandas  – A\n",
      "guide to setting up Pandas in your development\n",
      "environment, including common installation issues and\n",
      "best practices.\n",
      "Chapter 4: Data Structures in Pandas: Series\n",
      "and DataFrames  – A detailed look at Pandas’\n",
      "foundational data structures, Series and DataFrames,\n",
      "and their various use cases.\n",
      "Chapter 5: Indexing and Selection Techniques  –\n",
      "A guide to accessing, selectin\n",
      "---\n",
      "\n",
      "=== PAGE 19 - POTENTIAL TOC/CHAPTER ===\n",
      "Length: 1134 chars\n",
      "Content preview:\n",
      "processing text data within Pandas.\n",
      "Chapter 9: Pandas Date and Time Handling  – An\n",
      "overview of handling datetime data, working with\n",
      "time-based indexing, and analyzing temporal trends in\n",
      "datasets.\n",
      "Chapter 10: Mastering Data Import and Export\n",
      "in Pandas for AI and Data Science –Learn to import\n",
      "data from CSV, Excel, SQL, and JSON, export for\n",
      "reporting with Pandas.\n",
      "Chapter 11: Essential Data Exploration\n",
      "Techniques in Pandas –Delve into Pandas’ versatile\n",
      "tools for importing and exporting data from various\n",
      "formats, including CSV, Excel, SQL, JSON, and HTML.\n",
      "Chapter 12: Data Cleaning and Preprocessing\n",
      "---\n",
      "\n",
      "=== CONTENT ANALYSIS ===\n",
      "\n",
      "Page_2:\n",
      "  Lines: 13, Words: 83\n",
      "  Code indicators: 0\n",
      "  Pandas terms: 0\n",
      "\n",
      "Page_50:\n",
      "  Lines: 12, Words: 94\n",
      "  Code indicators: 0\n",
      "  Pandas terms: 5\n",
      "\n",
      "Page_100:\n",
      "  Lines: 17, Words: 105\n",
      "  Code indicators: 0\n",
      "  Pandas terms: 1\n",
      "\n",
      "Page_200:\n",
      "  Lines: 27, Words: 206\n",
      "  Code indicators: 1\n",
      "  Pandas terms: 3\n",
      "\n",
      "Page_300:\n",
      "  Lines: 18, Words: 149\n",
      "  Code indicators: 0\n",
      "  Pandas terms: 2\n",
      "\n",
      "Page_472:\n",
      "  Lines: 22, Words: 169\n",
      "  Code indicators: 0\n",
      "  Pandas terms: 9\n"
     ]
    }
   ],
   "source": [
    "# Chunk 3: Content Pattern Analysis\n",
    "\n",
    "# Find Table of Contents and Chapter Structure\n",
    "def find_toc_and_chapters(pdf_path, start_page=3, end_page=20):\n",
    "    \"\"\"Find TOC and identify chapter patterns\"\"\"\n",
    "    \n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        \n",
    "        for page_num in range(start_page, min(end_page, len(pdf_reader.pages))):\n",
    "            text = pdf_reader.pages[page_num].extract_text()\n",
    "            \n",
    "            # Look for TOC indicators\n",
    "            if any(indicator in text.lower() for indicator in ['contents', 'chapter', 'introduction']):\n",
    "                print(f\"\\n=== PAGE {page_num} - POTENTIAL TOC/CHAPTER ===\")\n",
    "                print(f\"Length: {len(text)} chars\")\n",
    "                print(\"Content preview:\")\n",
    "                print(text[:600])\n",
    "                print(\"---\")\n",
    "\n",
    "# Analyze text patterns in content pages\n",
    "def analyze_content_patterns(samples):\n",
    "    \"\"\"Analyze patterns in extracted text\"\"\"\n",
    "    \n",
    "    print(\"\\n=== CONTENT ANALYSIS ===\")\n",
    "    for page_name, content in samples.items():\n",
    "        if content and len(content) > 200:  # Only analyze substantial content\n",
    "            \n",
    "            # Count different elements\n",
    "            lines = content.split('\\n')\n",
    "            words = content.split()\n",
    "            \n",
    "            # Look for code patterns\n",
    "            code_indicators = content.count('import ') + content.count('pd.') + content.count('df.')\n",
    "            \n",
    "            # Look for pandas-specific content\n",
    "            pandas_terms = sum([content.lower().count(term) for term in \n",
    "                              ['dataframe', 'series', 'pandas', 'groupby', 'merge']])\n",
    "            \n",
    "            print(f\"\\n{page_name}:\")\n",
    "            print(f\"  Lines: {len(lines)}, Words: {len(words)}\")\n",
    "            print(f\"  Code indicators: {code_indicators}\")\n",
    "            print(f\"  Pandas terms: {pandas_terms}\")\n",
    "\n",
    "# Run analyses\n",
    "find_toc_and_chapters(PDF_FILE)\n",
    "analyze_content_patterns(page_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fd86adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPLETE TABLE OF CONTENTS ===\n",
      "TABLE OF CONTENTS\n",
      "TABLE OF\n",
      "CONTENTS………………………………………………………\n",
      "…………………………4          \n",
      "PREF ACE…………………………………………………………\n",
      "………………………………………….7        \n",
      "INTRODUCTION…………………………………………………\n",
      "………………………………………9          \n",
      "CHAPTER 1 :\n",
      "INTRODUCTION TO\n",
      "PANDAS………………………………………….………………\n",
      "………...11                 \n",
      "CHAPTER 2 :\n",
      "WHY USE PANDAS? IMPOR TANCE IN DATA\n",
      "ANAL YSIS……………………………20  \n",
      "CHAPTER 3 :\n",
      "INSTALLING AND SETTING UP\n",
      "PANDAS………………………….……………………….26\n",
      "CHAPTER 4 :\n",
      "DATA STRUCTURES IN PANDAS: SERIE S AND\n",
      "DATAFRAMES…………….……30\n",
      "CHAPTER 5 :\n",
      "INDEXING AND SELECTION\n",
      "TECHNIQUES…………………………….…………..……50\n",
      "CHAPTER 6 :\n",
      "PANDAS DATA TYPES AND\n",
      "CONVERSIONS………………………………………………80\n",
      " \n",
      "CHAPTER 7 :\n",
      "HANDLING MISSING DATA IN\n",
      "PANDAS………………………………………..…..……100  \n",
      "CHAPTER 8 :\n",
      "WORKING WITH TEXT\n",
      "DATA………………………………………….……………………\n",
      "…128\n",
      "CHAPTER 9 :\n",
      "PANDAS DATE AND TIME\n",
      "HANDLING………………………………………………….…\n",
      "152\n",
      "CHAPTER 10 :\n",
      "MASTERING DATA IMPOR T AND EXPOR T IN PANDAS\n",
      "FOR AI……….………163\n",
      "CHAPTER 11 :   \n",
      "ESSENTIAL DATA EXPL ORATION TECHNIQUES IN\n",
      "PANDAS…….……………182    \n",
      "CHAPTER   12 :   \n",
      "DATA CLEANING AND\n",
      "PREPROCESSING………………………………..………………\n",
      "206    CHAPTER 13 :\n",
      "PANDAS AGGREGA TION AND GROUPB Y\n",
      "OPER ATIONS……………..……..……218 CHAPTER 14 :\n",
      "RESHAPING AND PIVOTING\n",
      "DATA………….……………………………………….…….245\n",
      "CHAPTER 15 :\n",
      "MERGING, JOINING, AND CONCA TENA TION IN\n",
      "PANDAS………………………287\n",
      "CHAPTER 16 :\n",
      "FILTERING AND CONDITIONALL Y SELECTING\n",
      "DATA………….……..…………296  \n",
      "CHAPTER 17 :\n",
      "SORTING AND ORDERING IN\n",
      "PANDAS………………………………….…………….…322\n",
      "CHAPTER 18 :\n",
      "VECTORIZED OPER ATIONS AND\n",
      "BROADCASTING……………………….………..333\n",
      "CHAPTER 19 :\n",
      "WORKING WITH CATEGORICAL\n",
      "DATA……………………..…………………….………341\n",
      "CHAPTER 20 :\n",
      "ADVANCED PANDAS\n",
      "TECHNIQUES……..……………………………………………\n",
      "……354\n",
      "CONCL USION……………………………………………………\n",
      "……………………..…………….365\n",
      "REFERENCES……………………………………………………\n",
      "……………………..…………….368\n",
      "PREF ACE\n",
      "Welcome to Mastering Pandas: A Comprehensive Guide\n",
      "to Data Analysis in Python , a journey into the heart of\n",
      "modern data science. This book is not just a guide; it’s your\n",
      "gateway to the world of data exploration, where powerful\n",
      "insights lie hidden within raw numbers and text. Here,\n",
      "Pandas transforms data analysis from a challenging task\n",
      "into an enlightening experience, empowering you to harness\n",
      "the power of data like never before.\n",
      "In an era wher e data drives everything from business\n",
      "decisions to scientiﬁc breakthr oughs, Pandas emer ges as\n",
      "the tool that makes sense of comple xity. Imagine being able\n",
      "to swiftly shape vast datasets, uncover meaningful patter ns,\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== CHAPTER CONTENT - PAGE 11 ===\n",
      "Length: 1632 characters\n",
      " 1: environmental science, data holds the answers, and pandas\n",
      " 2: is your toolkit to unlock them.\n",
      " 3: If you’re diving into data science, machine learning, deep\n",
      " 4: learning, or artiﬁcial intelligence, one library you absolutely\n",
      " 5: need to know is pandas . Real-world data rarely comes\n",
      " 6: clean and ready for analysis. Often, it’s messy, inconsistent,\n",
      " 7: and ﬁlled with gaps. To build powerful, accurate models, the\n",
      " 8: quality of your data matters as much as the algorithms you\n",
      " 9: use. And that’s where pandas comes in—a superb tool for\n",
      "10: data preprocessing, helping you transform raw data into\n",
      "11: high-quality datasets that are ready to fuel your insights and\n",
      "12: predictions.\n",
      "13: With pandas, you can \"play\" with your data as if it were in\n",
      "14: your hands. It allows you to manipulate, clean, and explor e\n",
      "15: data seamlessly, adapting it to suit your analytical  goals. In\n",
      "\n",
      "=== CHAPTER CONTENT - PAGE 25 ===\n",
      "Length: 916 characters\n",
      " 1: uncover insights within this data, you need a toolkit that can\n",
      " 2: quickly transform, organize, and analyze it in a way that’s\n",
      " 3: both eﬃcient and intuitive. This is where Pandas  comes in.\n",
      " 4: Pandas isn’t just another Python library; it’s the backbone of\n",
      " 5: the data science workﬂow, oﬀering unparalleled speed,\n",
      " 6: ﬂexibility, and ease of use. In this chapter, we’ll dive deep\n",
      " 7: into why Pandas is essential for data analysis, exploring its\n",
      " 8: role in the data science workﬂow, performance beneﬁts, and\n",
      " 9: integration with other Python libraries.\n",
      "10: The Role of P andas in the Data Science\n",
      "11: Workﬂow\n",
      "12: Data science involves more than just running calculations\n",
      "13: on data—it’s about shapin g, cleaning, and transfor ming data\n",
      "14: to reveal meaningful patter ns. Pandas plays a crucial role in\n",
      "15: this pr ocess, supporting every step of the data workﬂow :\n",
      "\n",
      "=== CHAPTER CONTENT - PAGE 60 ===\n",
      "Length: 931 characters\n",
      " 1: unique entry, making it a perfect structur e for managing\n",
      " 2: multi-dimensional data.\n",
      " 3: Key Features of DataF rames\n",
      " 4: Row and Column Labels  : Each row and column can have\n",
      " 5: unique labels, making data access more intuitive.\n",
      " 6: Mixed Data Types : Each column in a DataFrame can\n",
      " 7: hold a diﬀerent data type, unlike a matrix or array that\n",
      " 8: requires uniform types.\n",
      " 9: Built-in Functions : DataFrames come with a range\n",
      "10: of built-in methods for data manipulation, including\n",
      "11: ﬁltering, sorting, and merging.\n",
      "12: Series vs. DataF rames: Diﬀerences and Use\n",
      "13: Cases\n",
      "14: While Series  and DataFrames  are both essential data\n",
      "15: structures in Pandas, they serve distinct purposes and are\n",
      "\n",
      "=== CHAPTER CONTENT - PAGE 120 ===\n",
      "Length: 799 characters\n",
      " 1: To make all values numeric, we use pd.to_numeric()  on the\n",
      " 2: Values  column with errors=\"coerce\" . This argument\n",
      " 3: replaces any non-numeric values with NaN  (although, in this\n",
      " 4: case, all values are convertible, so no NaN  appears). After\n",
      " 5: this conversion, pandas updates the data type of the Values\n",
      " 6: column to int64 , making it consistent across all entries.\n",
      " 7: This conversion ensures that the data can now be processed\n",
      " 8: more eﬃciently as a numeric column, which is particularly\n",
      " 9: useful for analysis and computation tasks.\n",
      "10: Ensuring Consistency Across Columns\n",
      "11: Ensuring that data types are consistent across related\n",
      "12: columns is essential. For instance, if you have multiple\n",
      "13: columns representing numerical data, make sure they share\n",
      "14: the same data type:\n",
      "15: # Ensuring  consistent  data types across numerical\n",
      "\n",
      "=== CHAPTER CONTENT - PAGE 250 ===\n",
      "Length: 307 characters\n",
      " 1: This command will return True  for each row that is a\n",
      " 2: duplicate, allowing you to take further action if needed. To\n",
      " 3: get a quick count of duplicates, you can combine it with\n",
      " 4: sum() :\n",
      " 5: This is especially helpful for data cleaning, ensuring that\n",
      " 6: each record is unique unless intentional duplic ates are\n",
      " 7: requir ed.\n",
      "\n",
      "=== TEXT QUALITY ASSESSMENT ===\n",
      "Sample from Page 200:\n",
      "  Multiple spaces found: 0\n",
      "  Potential broken words: 9\n",
      "  First 200 chars: Using Timedelta  opens up new possibilities for handling\n",
      "time-based data, giving you the ﬂexibility to analyze and\n",
      "manipulate dates with precision. By incorporating Timedelta\n",
      " into your workﬂow, you c\n"
     ]
    }
   ],
   "source": [
    "# Chunk 4: Complete Structure Mapping\n",
    "\n",
    "# Extract complete Table of Contents\n",
    "def extract_complete_toc(pdf_path):\n",
    "    \"\"\"Extract full TOC from pages 4-8\"\"\"\n",
    "    toc_text = \"\"\n",
    "    \n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        \n",
    "        for page_num in range(4, 9):  # TOC likely spans pages 4-8\n",
    "            if page_num < len(pdf_reader.pages):\n",
    "                text = pdf_reader.pages[page_num].extract_text()\n",
    "                toc_text += text + \"\\n\"\n",
    "    \n",
    "    return toc_text\n",
    "\n",
    "# Sample actual chapter content\n",
    "def sample_chapter_content(pdf_path, chapter_pages=[11, 25, 60, 120, 250]):\n",
    "    \"\"\"Sample content from different chapters\"\"\"\n",
    "    \n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        \n",
    "        for page_num in chapter_pages:\n",
    "            if page_num < len(pdf_reader.pages):\n",
    "                text = pdf_reader.pages[page_num].extract_text()\n",
    "                \n",
    "                print(f\"\\n=== CHAPTER CONTENT - PAGE {page_num} ===\")\n",
    "                print(f\"Length: {len(text)} characters\")\n",
    "                \n",
    "                # Show first part for structure analysis\n",
    "                lines = text.split('\\n')[:15]  # First 15 lines\n",
    "                for i, line in enumerate(lines):\n",
    "                    if line.strip():  # Only show non-empty lines\n",
    "                        print(f\"{i+1:2d}: {line.strip()[:80]}\")\n",
    "\n",
    "# Extract and analyze\n",
    "print(\"=== COMPLETE TABLE OF CONTENTS ===\")\n",
    "full_toc = extract_complete_toc(PDF_FILE)\n",
    "print(full_toc)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "sample_chapter_content(PDF_FILE)\n",
    "\n",
    "# Quick text quality assessment\n",
    "print(\"\\n=== TEXT QUALITY ASSESSMENT ===\")\n",
    "sample_text = page_samples.get('Page_200', '')\n",
    "if sample_text:\n",
    "    # Check for common PDF extraction issues\n",
    "    spacing_issues = sample_text.count('  ')  # Multiple spaces\n",
    "    broken_words = len([word for word in sample_text.split() if len(word) == 1 and word.isalpha()])\n",
    "    \n",
    "    print(f\"Sample from Page 200:\")\n",
    "    print(f\"  Multiple spaces found: {spacing_issues}\")\n",
    "    print(f\"  Potential broken words: {broken_words}\")\n",
    "    print(f\"  First 200 chars: {sample_text[:200]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69abe16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Analysis Summary\n",
    "# Structure:\n",
    "\n",
    "# 473-page comprehensive pandas guide\n",
    "# 26 chapters covering basics to advanced topics (time series, performance, visualization)\n",
    "# Clear hierarchical organization with logical progression\n",
    "# Chapter 1 starts page 11, substantial content throughout\n",
    "\n",
    "# Content Quality:\n",
    "\n",
    "# Good pandas-specific content with code examples\n",
    "# Some spacing issues from PDF extraction (manageable)\n",
    "# Mixed explanatory text and code blocks\n",
    "# High information density in content pages\n",
    "\n",
    "# Key Findings for Chunking:\n",
    "\n",
    "# Section-based chunking will work best (follow chapter/subsection boundaries)\n",
    "# Code-context preservation needed (keep examples with explanations)\n",
    "# Text preprocessing required to fix spacing issues\n",
    "# Hierarchical metadata available (chapter numbers, topics)\n",
    "\n",
    "# Chunking Strategy Implications\n",
    "# Based on this analysis, our optimal approach will be:\n",
    "\n",
    "# Clean text during extraction (fix spacing)\n",
    "# Detect section boundaries (chapters, subsections)\n",
    "# Preserve code blocks with their context\n",
    "# Add metadata (chapter, topic, page numbers)\n",
    "# Variable chunk sizes based on content logical units\n",
    "\n",
    "# The document structure is ideal for semantic chunking rather than fixed-size chunking.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mygame",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
