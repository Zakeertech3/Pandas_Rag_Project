{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b2d60b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Structure Check:\n",
      "Project Root: c:\\Users\\MOHAMMED ZAKEER\\Downloads\\pandas_rag_project\n",
      "PDF File Path: c:\\Users\\MOHAMMED ZAKEER\\Downloads\\pandas_rag_project\\data\\raw\\mastering_pandas_2025.pdf\n",
      "PDF File Exists: True\n",
      "File Size: 29.36 MB\n"
     ]
    }
   ],
   "source": [
    "# 01_data_exploration.ipynb - Complete Document Analysis\n",
    "\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup paths\n",
    "PROJECT_ROOT = Path.cwd().parent if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
    "RAW_DATA_PATH = PROJECT_ROOT / 'data' / 'raw'\n",
    "PDF_FILE = RAW_DATA_PATH / 'mastering_pandas_2025.pdf'\n",
    "\n",
    "print(\"Project Structure Check:\")\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"PDF File Path: {PDF_FILE}\")\n",
    "print(f\"PDF File Exists: {PDF_FILE.exists()}\")\n",
    "\n",
    "if PDF_FILE.exists():\n",
    "    file_size = PDF_FILE.stat().st_size\n",
    "    print(f\"File Size: {file_size / (1024*1024):.2f} MB\")\n",
    "else:\n",
    "    print(\"ERROR: PDF file not found!\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0000bae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PDF Structure:\n",
      "Total Pages: 473\n",
      "\n",
      "Metadata:\n",
      "/Author: Yildiz, Muslum\n",
      "/CreationDate: D:20250520051054+00'00'\n",
      "/Creator: calibre 7.16.0\n",
      "/ModDate: D:20250520051054+00'00'\n",
      "/Producer: calibre 7.16.0\n",
      "/Title: MASTERING PANDAS: A Comprehensive Guide to Data Analysis in Python\n"
     ]
    }
   ],
   "source": [
    "# PDF Structure Analysis\n",
    "with open(PDF_FILE, 'rb') as file:\n",
    "    pdf_reader = PyPDF2.PdfReader(file)\n",
    "    total_pages = len(pdf_reader.pages)\n",
    "    print(f\"\\nPDF Structure:\")\n",
    "    print(f\"Total Pages: {total_pages}\")\n",
    "    \n",
    "    if pdf_reader.metadata:\n",
    "        print(f\"\\nMetadata:\")\n",
    "        for key, value in pdf_reader.metadata.items():\n",
    "            print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f96a871d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing content quality across 473 pages...\n",
      "\n",
      "Content Analysis Results:\n",
      "Analyzed 99 pages\n",
      "\n",
      "Content Type Distribution:\n",
      "content_type\n",
      "general       61\n",
      "conceptual    25\n",
      "code_heavy     7\n",
      "navigation     5\n",
      "minimal        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Content Quality Statistics:\n",
      "Average words per page: 131.1\n",
      "Pages with substantial content (>500 chars): 79\n",
      "Pages with code content: 25\n",
      "Pages with pandas content: 74\n"
     ]
    }
   ],
   "source": [
    "# Content Quality Analysis Function\n",
    "def analyze_page_content(pdf_path, sample_size=50):\n",
    "    \"\"\"Analyze content quality across entire document\"\"\"\n",
    "    \n",
    "    content_analysis = []\n",
    "    \n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        total_pages = len(pdf_reader.pages)\n",
    "        \n",
    "        # Sample pages evenly across document\n",
    "        if sample_size > total_pages:\n",
    "            sample_pages = list(range(total_pages))\n",
    "        else:\n",
    "            step = total_pages // sample_size\n",
    "            sample_pages = list(range(0, total_pages, step))[:sample_size]\n",
    "        \n",
    "        for page_num in sample_pages:\n",
    "            try:\n",
    "                text = pdf_reader.pages[page_num].extract_text()\n",
    "                \n",
    "                if text.strip():\n",
    "                    # Content quality metrics\n",
    "                    char_count = len(text)\n",
    "                    word_count = len(text.split())\n",
    "                    line_count = len(text.split('\\n'))\n",
    "                    \n",
    "                    # Technical content indicators\n",
    "                    code_patterns = ['import ', 'pd.', 'df.', 'print(', '=', 'def ', 'class ']\n",
    "                    code_score = sum(text.count(pattern) for pattern in code_patterns)\n",
    "                    \n",
    "                    # Pandas-specific content\n",
    "                    pandas_terms = ['DataFrame', 'Series', 'pandas', 'groupby', 'merge', 'concat']\n",
    "                    pandas_score = sum(text.lower().count(term.lower()) for term in pandas_terms)\n",
    "                    \n",
    "                    # Content type classification\n",
    "                    if char_count < 200:\n",
    "                        content_type = 'minimal'\n",
    "                    elif 'TABLE OF CONTENTS' in text.upper() or 'CHAPTER' in text.upper()[:100]:\n",
    "                        content_type = 'navigation'\n",
    "                    elif code_score > 3:\n",
    "                        content_type = 'code_heavy'\n",
    "                    elif pandas_score > 2:\n",
    "                        content_type = 'conceptual'\n",
    "                    else:\n",
    "                        content_type = 'general'\n",
    "                    \n",
    "                    content_analysis.append({\n",
    "                        'page': page_num,\n",
    "                        'char_count': char_count,\n",
    "                        'word_count': word_count,\n",
    "                        'line_count': line_count,\n",
    "                        'code_score': code_score,\n",
    "                        'pandas_score': pandas_score,\n",
    "                        'content_type': content_type,\n",
    "                        'text_preview': text[:200].replace('\\n', ' ')\n",
    "                    })\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing page {page_num}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(content_analysis)\n",
    "\n",
    "# Run comprehensive content analysis\n",
    "print(f\"\\nAnalyzing content quality across {total_pages} pages...\")\n",
    "content_df = analyze_page_content(PDF_FILE, sample_size=100)\n",
    "\n",
    "print(f\"\\nContent Analysis Results:\")\n",
    "print(f\"Analyzed {len(content_df)} pages\")\n",
    "print(f\"\\nContent Type Distribution:\")\n",
    "print(content_df['content_type'].value_counts())\n",
    "\n",
    "print(f\"\\nContent Quality Statistics:\")\n",
    "print(f\"Average words per page: {content_df['word_count'].mean():.1f}\")\n",
    "print(f\"Pages with substantial content (>500 chars): {(content_df['char_count'] > 500).sum()}\")\n",
    "print(f\"Pages with code content: {(content_df['code_score'] > 0).sum()}\")\n",
    "print(f\"Pages with pandas content: {(content_df['pandas_score'] > 0).sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04616545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valuable Content Regions:\n",
      "Substantial content pages: 79\n",
      "Conceptual content pages: 25\n",
      "Code-heavy pages: 7\n",
      "Conceptual content range: pages 8-364\n",
      "Code content range: pages 36-196\n",
      "\n",
      "Document Structure Analysis:\n",
      "Chapter 1 found on page 4\n",
      "Chapter 2 found on page 4\n",
      "Chapter 3 found on page 4\n",
      "Table of Contents found on page 4\n",
      "Chapter 4 found on page 5\n",
      "Chapter 5 found on page 5\n",
      "Chapter 6 found on page 5\n",
      "Chapter 7 found on page 5\n",
      "Chapter 8 found on page 5\n",
      "Chapter 9 found on page 5\n",
      "Chapter 10 found on page 6\n",
      "Chapter 11 found on page 6\n",
      "Chapter 12 found on page 6\n",
      "Chapter 13 found on page 6\n",
      "Chapter 14 found on page 6\n",
      "Chapter 15 found on page 6\n",
      "Chapter 16 found on page 6\n",
      "Chapter 17 found on page 7\n",
      "Chapter 18 found on page 7\n",
      "Chapter 19 found on page 7\n",
      "Chapter 20 found on page 7\n",
      "Chapter 1 found on page 12\n",
      "Chapter 1 found on page 17\n",
      "Chapter 2 found on page 18\n",
      "Chapter 3 found on page 18\n",
      "Chapter 4 found on page 18\n",
      "Chapter 5 found on page 18\n",
      "Chapter 6 found on page 18\n",
      "Chapter 7 found on page 18\n",
      "Chapter 8 found on page 18\n",
      "Chapter 9 found on page 19\n",
      "Chapter 10 found on page 19\n",
      "Chapter 11 found on page 19\n",
      "Chapter 12 found on page 19\n",
      "Chapter 13 found on page 19\n",
      "Chapter 14 found on page 19\n",
      "Chapter 15 found on page 20\n",
      "Chapter 16 found on page 20\n",
      "Chapter 17 found on page 20\n",
      "Chapter 18 found on page 20\n",
      "Chapter 19 found on page 20\n",
      "Chapter 20 found on page 20\n",
      "Chapter 2 found on page 24\n",
      "Chapter 3 found on page 35\n",
      "Chapter 4 found on page 40\n",
      "\n",
      "Content Extraction Recommendations:\n",
      "Recommended content extraction range: pages 8 to 473\n",
      "High-value pages identified: 16\n",
      "Estimated valuable content: 3.4% of document\n",
      "\n",
      "Content analysis saved to: c:\\Users\\MOHAMMED ZAKEER\\Downloads\\pandas_rag_project\\data\\processed\\content_analysis.csv\n",
      "\n",
      "Text Quality Assessment:\n",
      "\n",
      "Page 8 (conceptual):\n",
      "  Length: 677 chars, 113 words\n",
      "  Preview: PREF ACE Welcome to Mastering Pandas: A Comprehensive Guide to Data Analysis in Python , a journey into the heart of modern data science. This book is not just a guide; it’s your gateway to the world \n",
      "\n",
      "Page 12 (conceptual):\n",
      "  Length: 1114 chars, 178 words\n",
      "  Preview: With pandas, you’r e not just crunching numbers; you’r e uncovering patter ns, predicting trends, and making data come alive in a way that drives r eal-world impact. What makes Mastering Pandas  uniqu\n",
      "\n",
      "Page 16 (conceptual):\n",
      "  Length: 1710 chars, 252 words\n",
      "  Preview: of tackling everything from basic exploration to deep statistical analysis. The heart of Pandas is its DataF rame object, a fast and eﬃcient data structur e with integrated indexing, designed to handl\n",
      "\n",
      "Data exploration complete. Ready for chunking strategy development.\n"
     ]
    }
   ],
   "source": [
    "# Identify valuable content regions\n",
    "substantial_pages = content_df[content_df['char_count'] > 500]\n",
    "conceptual_pages = content_df[content_df['content_type'] == 'conceptual']\n",
    "code_pages = content_df[content_df['content_type'] == 'code_heavy']\n",
    "\n",
    "print(f\"\\nValuable Content Regions:\")\n",
    "print(f\"Substantial content pages: {len(substantial_pages)}\")\n",
    "print(f\"Conceptual content pages: {len(conceptual_pages)}\")\n",
    "print(f\"Code-heavy pages: {len(code_pages)}\")\n",
    "\n",
    "if len(conceptual_pages) > 0:\n",
    "    print(f\"Conceptual content range: pages {conceptual_pages['page'].min()}-{conceptual_pages['page'].max()}\")\n",
    "if len(code_pages) > 0:\n",
    "    print(f\"Code content range: pages {code_pages['page'].min()}-{code_pages['page'].max()}\")\n",
    "\n",
    "# Document structure detection\n",
    "def detect_document_structure(pdf_path):\n",
    "    \"\"\"Detect chapters, sections, and document organization\"\"\"\n",
    "    \n",
    "    structure_info = []\n",
    "    \n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        \n",
    "        for page_num in range(min(50, len(pdf_reader.pages))):  # First 50 pages for structure\n",
    "            try:\n",
    "                text = pdf_reader.pages[page_num].extract_text()\n",
    "                \n",
    "                # Look for structural elements\n",
    "                if 'CHAPTER' in text.upper():\n",
    "                    chapters = re.findall(r'CHAPTER\\s+(\\d+)', text.upper())\n",
    "                    for chapter in chapters:\n",
    "                        structure_info.append({\n",
    "                            'page': page_num,\n",
    "                            'type': 'chapter',\n",
    "                            'number': chapter,\n",
    "                            'context': text[:300]\n",
    "                        })\n",
    "                \n",
    "                if 'TABLE OF CONTENTS' in text.upper():\n",
    "                    structure_info.append({\n",
    "                        'page': page_num,\n",
    "                        'type': 'toc',\n",
    "                        'number': None,\n",
    "                        'context': text[:500]\n",
    "                    })\n",
    "                    \n",
    "            except Exception as e:\n",
    "                continue\n",
    "    \n",
    "    return structure_info\n",
    "\n",
    "print(f\"\\nDocument Structure Analysis:\")\n",
    "structure = detect_document_structure(PDF_FILE)\n",
    "\n",
    "for item in structure:\n",
    "    if item['type'] == 'chapter':\n",
    "        print(f\"Chapter {item['number']} found on page {item['page']}\")\n",
    "    elif item['type'] == 'toc':\n",
    "        print(f\"Table of Contents found on page {item['page']}\")\n",
    "\n",
    "# Content extraction recommendations\n",
    "print(f\"\\nContent Extraction Recommendations:\")\n",
    "\n",
    "# Find the main content start\n",
    "main_content_start = 11  # Default from your analysis\n",
    "if len(conceptual_pages) > 0:\n",
    "    main_content_start = min(conceptual_pages['page'].min(), main_content_start)\n",
    "\n",
    "# Find content-rich regions\n",
    "content_rich_pages = content_df[\n",
    "    (content_df['char_count'] > 800) & \n",
    "    (content_df['content_type'].isin(['conceptual', 'code_heavy']))\n",
    "]['page'].tolist()\n",
    "\n",
    "print(f\"Recommended content extraction range: pages {main_content_start} to {total_pages}\")\n",
    "print(f\"High-value pages identified: {len(content_rich_pages)}\")\n",
    "print(f\"Estimated valuable content: {len(content_rich_pages)/total_pages*100:.1f}% of document\")\n",
    "\n",
    "# Save analysis results\n",
    "output_dir = PROJECT_ROOT / 'data' / 'processed'\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "content_df.to_csv(output_dir / 'content_analysis.csv', index=False)\n",
    "print(f\"\\nContent analysis saved to: {output_dir / 'content_analysis.csv'}\")\n",
    "\n",
    "# Text quality assessment\n",
    "sample_pages = content_df[content_df['content_type'] == 'conceptual'].head(3)\n",
    "\n",
    "print(f\"\\nText Quality Assessment:\")\n",
    "for _, page in sample_pages.iterrows():\n",
    "    print(f\"\\nPage {page['page']} ({page['content_type']}):\")\n",
    "    print(f\"  Length: {page['char_count']} chars, {page['word_count']} words\")\n",
    "    print(f\"  Preview: {page['text_preview']}\")\n",
    "\n",
    "print(f\"\\nData exploration complete. Ready for chunking strategy development.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab20a923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mygame",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
