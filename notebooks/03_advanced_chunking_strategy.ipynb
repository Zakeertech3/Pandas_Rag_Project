{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "259e0a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADVANCED CHUNK OPTIMIZATION AND PREPARATION\n",
      "============================================================\n",
      "Optimizing 85 chunks for retrieval and quiz generation\n",
      "Loaded comprehensive chunk data:\n",
      "  Total chunks: 85\n",
      "  Total tokens: 80,277\n",
      "  Utilization: 100.0%\n",
      "\n",
      "Chunk distribution by tier:\n",
      "  Tier 1 Primary: 13 chunks, 1326 avg tokens\n",
      "  Tier 2 Secondary: 16 chunks, 1099 avg tokens\n",
      "  Tier 3 Reference: 47 chunks, 873 avg tokens\n",
      "  Tier 4 Context: 9 chunks, 493 avg tokens\n",
      "\n",
      "Quality metrics loaded:\n",
      "  High pandas chunks: 13\n",
      "  Code-heavy chunks: 8\n",
      "  Quiz potential chunks: 31\n",
      "  Large comprehensive chunks: 37\n",
      "\n",
      "Ready to optimize chunks for dual-purpose system:\n",
      "  1. Enhanced retrieval performance\n",
      "  2. Rich quiz content generation\n",
      "  3. Intelligent content tagging and categorization\n"
     ]
    }
   ],
   "source": [
    "# Setup and Load Comprehensive Chunks\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup paths\n",
    "PROJECT_ROOT = Path.cwd().parent if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
    "PROCESSED_DATA_PATH = PROJECT_ROOT / 'data' / 'processed'\n",
    "\n",
    "print(\"ADVANCED CHUNK OPTIMIZATION AND PREPARATION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Optimizing 85 chunks for retrieval and quiz generation\")\n",
    "\n",
    "# Load comprehensive chunking results\n",
    "chunks_file = PROCESSED_DATA_PATH / 'tiered_chunks_comprehensive.pkl'\n",
    "summary_file = PROCESSED_DATA_PATH / 'chunking_summary.json'\n",
    "tier_collections_file = PROCESSED_DATA_PATH / 'tier_collections.pkl'\n",
    "\n",
    "if not chunks_file.exists():\n",
    "    print(\"ERROR: Chunking results not found!\")\n",
    "    print(\"Please run notebook 02_tiered_content_processing.ipynb first\")\n",
    "    exit()\n",
    "\n",
    "# Load all data\n",
    "with open(chunks_file, 'rb') as f:\n",
    "    all_chunks = pickle.load(f)\n",
    "\n",
    "with open(summary_file, 'r') as f:\n",
    "    chunking_summary = json.load(f)\n",
    "\n",
    "with open(tier_collections_file, 'rb') as f:\n",
    "    tier_collections = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded comprehensive chunk data:\")\n",
    "print(f\"  Total chunks: {len(all_chunks)}\")\n",
    "print(f\"  Total tokens: {chunking_summary['total_tokens']:,}\")\n",
    "print(f\"  Utilization: {chunking_summary['utilization_efficiency']:.1f}%\")\n",
    "\n",
    "print(f\"\\nChunk distribution by tier:\")\n",
    "for tier, stats in chunking_summary['tier_statistics'].items():\n",
    "    tier_name = tier.replace('_', ' ').title()\n",
    "    print(f\"  {tier_name}: {stats['chunk_count']} chunks, {stats['avg_tokens']:.0f} avg tokens\")\n",
    "\n",
    "print(f\"\\nQuality metrics loaded:\")\n",
    "quality = chunking_summary['quality_metrics']\n",
    "print(f\"  High pandas chunks: {quality['high_pandas_chunks']}\")\n",
    "print(f\"  Code-heavy chunks: {quality['code_heavy_chunks']}\")\n",
    "print(f\"  Quiz potential chunks: {quality['quiz_potential_chunks']}\")\n",
    "print(f\"  Large comprehensive chunks: {quality['large_chunks']}\")\n",
    "\n",
    "print(f\"\\nReady to optimize chunks for dual-purpose system:\")\n",
    "print(f\"  1. Enhanced retrieval performance\")\n",
    "print(f\"  2. Rich quiz content generation\")\n",
    "print(f\"  3. Intelligent content tagging and categorization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebaeb276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing advanced content analysis on all 85 chunks...\n",
      "  Enhanced 20/85 chunks\n",
      "  Enhanced 40/85 chunks\n",
      "  Enhanced 60/85 chunks\n",
      "  Enhanced 80/85 chunks\n",
      "  Enhanced 85/85 chunks\n",
      "\n",
      "Advanced content analysis completed!\n",
      "\n",
      "ENHANCEMENT ANALYSIS:\n",
      "========================================\n",
      "Quiz generation potential:\n",
      "  Multiple Choice: 26 chunks\n",
      "  Code Completion: 29 chunks\n",
      "  True False: 53 chunks\n",
      "  Fill Blank: 65 chunks\n",
      "  Scenario Based: 36 chunks\n",
      "\n",
      "Pandas function coverage:\n",
      "  Data Inspection: 71 chunks\n",
      "  Data Selection: 77 chunks\n",
      "  Data Manipulation: 24 chunks\n",
      "  Data Analysis: 38 chunks\n",
      "  Data Cleaning: 16 chunks\n",
      "  Data Loading: 6 chunks\n",
      "\n",
      "Optimization tag distribution:\n",
      "  High Retrieval Value: 24 chunks (28.2%)\n",
      "  Excellent Quiz Source: 72 chunks (84.7%)\n",
      "  Technical Reference: 13 chunks (15.3%)\n",
      "  Comprehensive Content: 37 chunks (43.5%)\n",
      "  Multi Purpose: 40 chunks (47.1%)\n",
      "\n",
      "Content score statistics:\n",
      "  Retrieval scores - Avg: 3.8, Max: 19.8\n",
      "  Quiz scores - Avg: 5.9, Max: 14.4\n",
      "  Technical scores - Avg: 0.9, Max: 6.9\n",
      "\n",
      "Chunk enhancement completed successfully!\n",
      "All 85 chunks now optimized for dual-purpose system\n"
     ]
    }
   ],
   "source": [
    "# Advanced Content Analysis and Enhancement\n",
    "\n",
    "def analyze_chunk_content_depth(chunk):\n",
    "    \"\"\"\n",
    "    Deep content analysis for enhanced retrieval and quiz generation\n",
    "    \"\"\"\n",
    "    text = chunk['content']\n",
    "    \n",
    "    # Advanced pandas function detection\n",
    "    pandas_functions = {\n",
    "        'data_loading': ['read_csv', 'read_excel', 'read_json', 'read_sql', 'read_html'],\n",
    "        'data_inspection': ['head', 'tail', 'info', 'describe', 'shape', 'dtypes', 'columns'],\n",
    "        'data_selection': ['loc', 'iloc', 'query', 'filter', 'where', 'mask'],\n",
    "        'data_manipulation': ['groupby', 'merge', 'concat', 'join', 'pivot', 'melt'],\n",
    "        'data_cleaning': ['dropna', 'fillna', 'drop_duplicates', 'replace', 'astype'],\n",
    "        'data_analysis': ['value_counts', 'unique', 'nunique', 'sort_values', 'sort_index'],\n",
    "        'data_visualization': ['plot', 'hist', 'scatter', 'boxplot', 'bar']\n",
    "    }\n",
    "    \n",
    "    function_coverage = {}\n",
    "    for category, functions in pandas_functions.items():\n",
    "        count = sum(len(re.findall(rf'\\b{func}\\b', text, re.IGNORECASE)) for func in functions)\n",
    "        function_coverage[category] = count\n",
    "    \n",
    "    # Quiz content type detection\n",
    "    quiz_indicators = {\n",
    "        'conceptual_questions': len(re.findall(r'(what\\s+is|define|concept|principle|understand)', text, re.IGNORECASE)),\n",
    "        'practical_examples': len(re.findall(r'(example|for\\s+instance|let\\'s\\s+try|consider)', text, re.IGNORECASE)),\n",
    "        'code_exercises': len(re.findall(r'(import|pd\\.|df\\.|print\\s*\\(|\\=\\s*pd\\.)', text, re.IGNORECASE)),\n",
    "        'comparison_content': len(re.findall(r'(difference|compare|versus|vs\\.|better|alternative)', text, re.IGNORECASE)),\n",
    "        'step_by_step': len(re.findall(r'(step|first|then|next|finally|process)', text, re.IGNORECASE)),\n",
    "        'best_practices': len(re.findall(r'(best\\s+practice|recommend|should|important|tip)', text, re.IGNORECASE))\n",
    "    }\n",
    "    \n",
    "    # Content difficulty assessment\n",
    "    difficulty_indicators = {\n",
    "        'beginner': len(re.findall(r'(basic|simple|introduction|getting\\s+started|beginner)', text, re.IGNORECASE)),\n",
    "        'intermediate': len(re.findall(r'(advanced|complex|sophisticated|optimization)', text, re.IGNORECASE)),\n",
    "        'expert': len(re.findall(r'(expert|professional|production|performance|scale)', text, re.IGNORECASE))\n",
    "    }\n",
    "    \n",
    "    # Technical depth indicators\n",
    "    technical_depth = {\n",
    "        'syntax_heavy': chunk['features']['has_code_examples'],\n",
    "        'concept_heavy': chunk['features']['conceptual_density'] > 3,\n",
    "        'method_focused': function_coverage['data_manipulation'] > 2,\n",
    "        'practical_oriented': quiz_indicators['practical_examples'] > 2,\n",
    "        'theoretical_content': quiz_indicators['conceptual_questions'] > 2\n",
    "    }\n",
    "    \n",
    "    # Retrieval optimization features\n",
    "    retrieval_features = {\n",
    "        'keyword_density': len(re.findall(r'(pandas|dataframe|series|index)', text, re.IGNORECASE)),\n",
    "        'context_richness': chunk['page_count'] > 2,\n",
    "        'example_rich': quiz_indicators['practical_examples'] > 1,\n",
    "        'comprehensive_coverage': chunk['token_count'] > 1000,\n",
    "        'multi_topic': sum(1 for count in function_coverage.values() if count > 0) > 3\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'function_coverage': function_coverage,\n",
    "        'quiz_indicators': quiz_indicators,\n",
    "        'difficulty_indicators': difficulty_indicators,\n",
    "        'technical_depth': technical_depth,\n",
    "        'retrieval_features': retrieval_features\n",
    "    }\n",
    "\n",
    "def categorize_chunk_for_quiz_generation(chunk, analysis):\n",
    "    \"\"\"\n",
    "    Categorize chunks for different types of quiz questions\n",
    "    \"\"\"\n",
    "    quiz_categories = []\n",
    "    \n",
    "    # Multiple choice potential\n",
    "    if (analysis['quiz_indicators']['conceptual_questions'] > 1 or \n",
    "        analysis['quiz_indicators']['comparison_content'] > 1):\n",
    "        quiz_categories.append('multiple_choice')\n",
    "    \n",
    "    # Code completion potential  \n",
    "    if (analysis['quiz_indicators']['code_exercises'] > 2 or\n",
    "        chunk['features']['has_code_examples']):\n",
    "        quiz_categories.append('code_completion')\n",
    "    \n",
    "    # True/false potential\n",
    "    if (analysis['quiz_indicators']['best_practices'] > 1 or\n",
    "        analysis['difficulty_indicators']['beginner'] > 1):\n",
    "        quiz_categories.append('true_false')\n",
    "    \n",
    "    # Fill in the blank potential\n",
    "    if (analysis['function_coverage']['data_manipulation'] > 1 or\n",
    "        analysis['function_coverage']['data_selection'] > 1):\n",
    "        quiz_categories.append('fill_blank')\n",
    "    \n",
    "    # Scenario-based potential\n",
    "    if (analysis['quiz_indicators']['practical_examples'] > 1 and\n",
    "        analysis['quiz_indicators']['step_by_step'] > 1):\n",
    "        quiz_categories.append('scenario_based')\n",
    "    \n",
    "    return quiz_categories\n",
    "\n",
    "def enhance_chunk_metadata(chunk):\n",
    "    \"\"\"\n",
    "    Add comprehensive metadata for dual-purpose optimization\n",
    "    \"\"\"\n",
    "    # Perform deep analysis\n",
    "    analysis = analyze_chunk_content_depth(chunk)\n",
    "    \n",
    "    # Categorize for quiz generation\n",
    "    quiz_categories = categorize_chunk_for_quiz_generation(chunk, analysis)\n",
    "    \n",
    "    # Determine primary focus areas\n",
    "    function_totals = analysis['function_coverage']\n",
    "    primary_functions = [category for category, count in function_totals.items() if count > 1]\n",
    "    \n",
    "    # Calculate content scores\n",
    "    content_scores = {\n",
    "        'retrieval_score': sum([\n",
    "            chunk['avg_pandas_score'] * 0.3,\n",
    "            analysis['retrieval_features']['keyword_density'] * 0.2,\n",
    "            analysis['retrieval_features']['comprehensive_coverage'] * 0.2,\n",
    "            analysis['retrieval_features']['example_rich'] * 0.15,\n",
    "            analysis['retrieval_features']['multi_topic'] * 0.15\n",
    "        ]),\n",
    "        'quiz_score': sum([\n",
    "            sum(analysis['quiz_indicators'].values()) * 0.4,\n",
    "            len(quiz_categories) * 0.3,\n",
    "            chunk['avg_quiz_score'] * 0.3\n",
    "        ]),\n",
    "        'technical_score': sum([\n",
    "            chunk['avg_code_score'] * 0.4,\n",
    "            analysis['function_coverage']['data_manipulation'] * 0.3,\n",
    "            analysis['technical_depth']['syntax_heavy'] * 0.3\n",
    "        ])\n",
    "    }\n",
    "    \n",
    "    # Enhanced metadata\n",
    "    enhanced_metadata = {\n",
    "        'content_analysis': analysis,\n",
    "        'quiz_categories': quiz_categories,\n",
    "        'primary_functions': primary_functions,\n",
    "        'content_scores': content_scores,\n",
    "        'optimization_tags': {\n",
    "            'high_retrieval_value': content_scores['retrieval_score'] > 5,\n",
    "            'excellent_quiz_source': content_scores['quiz_score'] > 3,\n",
    "            'technical_reference': content_scores['technical_score'] > 2,\n",
    "            'comprehensive_content': chunk['token_count'] > 1000,\n",
    "            'multi_purpose': len(quiz_categories) > 2\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return enhanced_metadata\n",
    "\n",
    "print(\"Performing advanced content analysis on all 85 chunks...\")\n",
    "\n",
    "# Enhance all chunks with comprehensive metadata\n",
    "enhanced_chunks = []\n",
    "for i, chunk in enumerate(all_chunks):\n",
    "    enhanced_metadata = enhance_chunk_metadata(chunk)\n",
    "    \n",
    "    # Create enhanced chunk record\n",
    "    enhanced_chunk = {\n",
    "        **chunk,  # Original chunk data\n",
    "        **enhanced_metadata  # Enhanced analysis\n",
    "    }\n",
    "    \n",
    "    enhanced_chunks.append(enhanced_chunk)\n",
    "    \n",
    "    # Progress indicator\n",
    "    if (i + 1) % 20 == 0 or i == len(all_chunks) - 1:\n",
    "        print(f\"  Enhanced {i + 1}/{len(all_chunks)} chunks\")\n",
    "\n",
    "print(f\"\\nAdvanced content analysis completed!\")\n",
    "\n",
    "# Analyze enhancement results\n",
    "print(f\"\\nENHANCEMENT ANALYSIS:\")\n",
    "print(f\"=\" * 40)\n",
    "\n",
    "# Quiz category distribution\n",
    "all_quiz_categories = []\n",
    "for chunk in enhanced_chunks:\n",
    "    all_quiz_categories.extend(chunk['quiz_categories'])\n",
    "\n",
    "quiz_category_counts = {}\n",
    "for category in all_quiz_categories:\n",
    "    quiz_category_counts[category] = quiz_category_counts.get(category, 0) + 1\n",
    "\n",
    "print(f\"Quiz generation potential:\")\n",
    "for category, count in quiz_category_counts.items():\n",
    "    print(f\"  {category.replace('_', ' ').title()}: {count} chunks\")\n",
    "\n",
    "# Function coverage analysis\n",
    "function_coverage_summary = defaultdict(int)\n",
    "for chunk in enhanced_chunks:\n",
    "    for category, count in chunk['content_analysis']['function_coverage'].items():\n",
    "        if count > 0:\n",
    "            function_coverage_summary[category] += 1\n",
    "\n",
    "print(f\"\\nPandas function coverage:\")\n",
    "for category, chunk_count in function_coverage_summary.items():\n",
    "    print(f\"  {category.replace('_', ' ').title()}: {chunk_count} chunks\")\n",
    "\n",
    "# Optimization tag analysis\n",
    "optimization_stats = {\n",
    "    'high_retrieval_value': 0,\n",
    "    'excellent_quiz_source': 0, \n",
    "    'technical_reference': 0,\n",
    "    'comprehensive_content': 0,\n",
    "    'multi_purpose': 0\n",
    "}\n",
    "\n",
    "for chunk in enhanced_chunks:\n",
    "    for tag, value in chunk['optimization_tags'].items():\n",
    "        if value:\n",
    "            optimization_stats[tag] += 1\n",
    "\n",
    "print(f\"\\nOptimization tag distribution:\")\n",
    "for tag, count in optimization_stats.items():\n",
    "    percentage = (count / len(enhanced_chunks)) * 100\n",
    "    print(f\"  {tag.replace('_', ' ').title()}: {count} chunks ({percentage:.1f}%)\")\n",
    "\n",
    "# Content score analysis\n",
    "retrieval_scores = [chunk['content_scores']['retrieval_score'] for chunk in enhanced_chunks]\n",
    "quiz_scores = [chunk['content_scores']['quiz_score'] for chunk in enhanced_chunks]\n",
    "technical_scores = [chunk['content_scores']['technical_score'] for chunk in enhanced_chunks]\n",
    "\n",
    "print(f\"\\nContent score statistics:\")\n",
    "print(f\"  Retrieval scores - Avg: {np.mean(retrieval_scores):.1f}, Max: {np.max(retrieval_scores):.1f}\")\n",
    "print(f\"  Quiz scores - Avg: {np.mean(quiz_scores):.1f}, Max: {np.max(quiz_scores):.1f}\")\n",
    "print(f\"  Technical scores - Avg: {np.mean(technical_scores):.1f}, Max: {np.max(technical_scores):.1f}\")\n",
    "\n",
    "print(f\"\\nChunk enhancement completed successfully!\")\n",
    "print(f\"All 85 chunks now optimized for dual-purpose system\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d39ec93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating specialized chunk collections...\n",
      "Specialized collections created:\n",
      "  High Retrieval: 24 chunks\n",
      "  Quiz Generation: 72 chunks\n",
      "  Code Examples: 40 chunks\n",
      "  Conceptual: 8 chunks\n",
      "  Comprehensive: 37 chunks\n",
      "  Reference: 63 chunks\n",
      "\n",
      "Preparing quiz question bank structure...\n",
      "Quiz question bank prepared:\n",
      "  Multiple Choice: 26 chunks\n",
      "    - Beginner: 9 chunks\n",
      "    - Intermediate: 8 chunks\n",
      "    - Advanced: 9 chunks\n",
      "  Code Completion: 29 chunks\n",
      "    - Syntax: 23 chunks\n",
      "    - Functions: 2 chunks\n",
      "    - Practical: 4 chunks\n",
      "  True False: 53 chunks\n",
      "    - Concepts: 3 chunks\n",
      "    - Best Practices: 37 chunks\n",
      "    - Facts: 13 chunks\n",
      "  Fill Blank: 65 chunks\n",
      "    - Parameters: 45 chunks\n",
      "    - Methods: 20 chunks\n",
      "  Scenario Based: 36 chunks\n",
      "    - Data Analysis: 5 chunks\n",
      "    - Problem Solving: 7 chunks\n",
      "    - Real World: 24 chunks\n",
      "\n",
      "Calculating system readiness metrics...\n",
      "\n",
      "SYSTEM READINESS ANALYSIS:\n",
      "==================================================\n",
      "\n",
      "RETRIEVAL SYSTEM READINESS:\n",
      "  Total chunks available: 85\n",
      "  High-quality retrieval chunks: 24\n",
      "  Comprehensive content chunks: 37\n",
      "  Code example chunks: 40\n",
      "  Conceptual chunks: 8\n",
      "  Retrieval coverage score: 28.2%\n",
      "\n",
      "QUIZ SYSTEM READINESS:\n",
      "  Quiz-ready chunks: 72\n",
      "  Quiz types covered: 5/5\n",
      "  Difficulty levels: 3\n",
      "  Question generation potential: 209 total questions\n",
      "  Quiz coverage score: 84.7%\n",
      "\n",
      "CONTENT QUALITY METRICS:\n",
      "  Average tokens per chunk: 944\n",
      "  Average retrieval score: 3.8\n",
      "  Average quiz score: 5.9\n",
      "  Multi-purpose chunks: 40\n",
      "  PDF utilization efficiency: 100.0%\n",
      "\n",
      "IMPROVEMENT ANALYSIS:\n",
      "  Chunk count improvement: 6.5x (85 vs 13)\n",
      "  Content utilization: 100% vs ~16% (6.25x improvement)\n",
      "  Quiz generation capability: NEW FEATURE ADDED\n",
      "  Dual-purpose optimization: FULLY IMPLEMENTED\n",
      "\n",
      "Advanced chunk optimization completed!\n"
     ]
    }
   ],
   "source": [
    "# Final Chunk Optimization and Preparation\n",
    "\n",
    "def create_specialized_collections(enhanced_chunks):\n",
    "    \"\"\"\n",
    "    Create specialized chunk collections for different use cases\n",
    "    \"\"\"\n",
    "    collections = {\n",
    "        'high_retrieval': [],      # Best chunks for retrieval system\n",
    "        'quiz_generation': [],     # Best chunks for quiz creation\n",
    "        'code_examples': [],       # Code-heavy chunks for practical questions\n",
    "        'conceptual': [],          # Conceptual content for theory questions\n",
    "        'comprehensive': [],       # Large, multi-topic chunks\n",
    "        'reference': []           # Quick reference and lookup content\n",
    "    }\n",
    "    \n",
    "    for chunk in enhanced_chunks:\n",
    "        # High retrieval value chunks\n",
    "        if chunk['optimization_tags']['high_retrieval_value']:\n",
    "            collections['high_retrieval'].append(chunk)\n",
    "        \n",
    "        # Excellent quiz source chunks\n",
    "        if chunk['optimization_tags']['excellent_quiz_source']:\n",
    "            collections['quiz_generation'].append(chunk)\n",
    "        \n",
    "        # Code-heavy chunks\n",
    "        if (chunk['content_scores']['technical_score'] > 1 or \n",
    "            'code_completion' in chunk['quiz_categories']):\n",
    "            collections['code_examples'].append(chunk)\n",
    "        \n",
    "        # Conceptual chunks\n",
    "        if (chunk['avg_pandas_score'] > 5 and \n",
    "            chunk['content_analysis']['technical_depth']['concept_heavy']):\n",
    "            collections['conceptual'].append(chunk)\n",
    "        \n",
    "        # Comprehensive content chunks\n",
    "        if chunk['optimization_tags']['comprehensive_content']:\n",
    "            collections['comprehensive'].append(chunk)\n",
    "        \n",
    "        # Reference chunks (Tier 3 and some Tier 2)\n",
    "        if chunk['tier'] in ['tier_3_reference', 'tier_2_secondary']:\n",
    "            collections['reference'].append(chunk)\n",
    "    \n",
    "    return collections\n",
    "\n",
    "def create_quiz_question_bank_preparation(enhanced_chunks):\n",
    "    \"\"\"\n",
    "    Prepare chunks specifically for quiz question generation\n",
    "    \"\"\"\n",
    "    quiz_bank = {\n",
    "        'multiple_choice': {\n",
    "            'beginner': [],\n",
    "            'intermediate': [],\n",
    "            'advanced': []\n",
    "        },\n",
    "        'code_completion': {\n",
    "            'syntax': [],\n",
    "            'functions': [],\n",
    "            'practical': []\n",
    "        },\n",
    "        'true_false': {\n",
    "            'concepts': [],\n",
    "            'best_practices': [],\n",
    "            'facts': []\n",
    "        },\n",
    "        'fill_blank': {\n",
    "            'parameters': [],\n",
    "            'methods': [],\n",
    "            'syntax': []\n",
    "        },\n",
    "        'scenario_based': {\n",
    "            'data_analysis': [],\n",
    "            'problem_solving': [],\n",
    "            'real_world': []\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for chunk in enhanced_chunks:\n",
    "        # Determine difficulty level\n",
    "        difficulty_scores = chunk['content_analysis']['difficulty_indicators']\n",
    "        if difficulty_scores['beginner'] > difficulty_scores['intermediate']:\n",
    "            difficulty = 'beginner'\n",
    "        elif difficulty_scores['expert'] > 0:\n",
    "            difficulty = 'advanced'\n",
    "        else:\n",
    "            difficulty = 'intermediate'\n",
    "        \n",
    "        # Sort into appropriate quiz categories\n",
    "        for quiz_type in chunk['quiz_categories']:\n",
    "            if quiz_type == 'multiple_choice':\n",
    "                quiz_bank['multiple_choice'][difficulty].append(chunk)\n",
    "            \n",
    "            elif quiz_type == 'code_completion':\n",
    "                if chunk['content_scores']['technical_score'] > 2:\n",
    "                    quiz_bank['code_completion']['practical'].append(chunk)\n",
    "                elif chunk['content_analysis']['function_coverage']['data_manipulation'] > 1:\n",
    "                    quiz_bank['code_completion']['functions'].append(chunk)\n",
    "                else:\n",
    "                    quiz_bank['code_completion']['syntax'].append(chunk)\n",
    "            \n",
    "            elif quiz_type == 'true_false':\n",
    "                if chunk['content_analysis']['quiz_indicators']['best_practices'] > 1:\n",
    "                    quiz_bank['true_false']['best_practices'].append(chunk)\n",
    "                elif chunk['content_analysis']['quiz_indicators']['conceptual_questions'] > 1:\n",
    "                    quiz_bank['true_false']['concepts'].append(chunk)\n",
    "                else:\n",
    "                    quiz_bank['true_false']['facts'].append(chunk)\n",
    "            \n",
    "            elif quiz_type == 'fill_blank':\n",
    "                if chunk['content_analysis']['function_coverage']['data_manipulation'] > 1:\n",
    "                    quiz_bank['fill_blank']['methods'].append(chunk)\n",
    "                elif chunk['content_analysis']['function_coverage']['data_selection'] > 1:\n",
    "                    quiz_bank['fill_blank']['parameters'].append(chunk)\n",
    "                else:\n",
    "                    quiz_bank['fill_blank']['syntax'].append(chunk)\n",
    "            \n",
    "            elif quiz_type == 'scenario_based':\n",
    "                if chunk['content_analysis']['quiz_indicators']['practical_examples'] > 2:\n",
    "                    quiz_bank['scenario_based']['real_world'].append(chunk)\n",
    "                elif chunk['content_analysis']['quiz_indicators']['step_by_step'] > 2:\n",
    "                    quiz_bank['scenario_based']['problem_solving'].append(chunk)\n",
    "                else:\n",
    "                    quiz_bank['scenario_based']['data_analysis'].append(chunk)\n",
    "    \n",
    "    return quiz_bank\n",
    "\n",
    "def calculate_system_readiness_metrics(enhanced_chunks, collections, quiz_bank):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive readiness metrics for the dual-purpose system\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        'retrieval_system': {\n",
    "            'total_chunks': len(enhanced_chunks),\n",
    "            'high_quality_chunks': len(collections['high_retrieval']),\n",
    "            'comprehensive_chunks': len(collections['comprehensive']),\n",
    "            'code_example_chunks': len(collections['code_examples']),\n",
    "            'conceptual_chunks': len(collections['conceptual']),\n",
    "            'coverage_score': len(collections['high_retrieval']) / len(enhanced_chunks) * 100\n",
    "        },\n",
    "        'quiz_system': {\n",
    "            'total_quiz_chunks': len(collections['quiz_generation']),\n",
    "            'quiz_types_covered': len([qt for qt in quiz_bank.keys() if any(quiz_bank[qt].values() if isinstance(quiz_bank[qt], dict) else quiz_bank[qt])]),\n",
    "            'difficulty_levels': 3,  # beginner, intermediate, advanced\n",
    "            'question_generation_potential': sum(len(chunks) for category in quiz_bank.values() \n",
    "                                               for chunks in (category.values() if isinstance(category, dict) else [category])),\n",
    "            'quiz_coverage_score': len(collections['quiz_generation']) / len(enhanced_chunks) * 100\n",
    "        },\n",
    "        'content_quality': {\n",
    "            'avg_tokens_per_chunk': np.mean([chunk['token_count'] for chunk in enhanced_chunks]),\n",
    "            'avg_retrieval_score': np.mean([chunk['content_scores']['retrieval_score'] for chunk in enhanced_chunks]),\n",
    "            'avg_quiz_score': np.mean([chunk['content_scores']['quiz_score'] for chunk in enhanced_chunks]),\n",
    "            'multi_purpose_chunks': len([c for c in enhanced_chunks if c['optimization_tags']['multi_purpose']]),\n",
    "            'utilization_efficiency': 100.0  # 100% PDF utilization achieved\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"Creating specialized chunk collections...\")\n",
    "\n",
    "# Create specialized collections\n",
    "specialized_collections = create_specialized_collections(enhanced_chunks)\n",
    "\n",
    "print(f\"Specialized collections created:\")\n",
    "for collection_name, chunks in specialized_collections.items():\n",
    "    print(f\"  {collection_name.replace('_', ' ').title()}: {len(chunks)} chunks\")\n",
    "\n",
    "print(f\"\\nPreparing quiz question bank structure...\")\n",
    "\n",
    "# Create quiz question bank preparation\n",
    "quiz_question_bank = create_quiz_question_bank_preparation(enhanced_chunks)\n",
    "\n",
    "print(f\"Quiz question bank prepared:\")\n",
    "for quiz_type, categories in quiz_question_bank.items():\n",
    "    total_chunks = sum(len(chunks) for chunks in (categories.values() if isinstance(categories, dict) else [categories]))\n",
    "    print(f\"  {quiz_type.replace('_', ' ').title()}: {total_chunks} chunks\")\n",
    "    \n",
    "    if isinstance(categories, dict):\n",
    "        for category, chunks in categories.items():\n",
    "            if chunks:\n",
    "                print(f\"    - {category.replace('_', ' ').title()}: {len(chunks)} chunks\")\n",
    "\n",
    "print(f\"\\nCalculating system readiness metrics...\")\n",
    "\n",
    "# Calculate comprehensive readiness metrics\n",
    "readiness_metrics = calculate_system_readiness_metrics(enhanced_chunks, specialized_collections, quiz_question_bank)\n",
    "\n",
    "print(f\"\\nSYSTEM READINESS ANALYSIS:\")\n",
    "print(f\"=\" * 50)\n",
    "\n",
    "print(f\"\\nRETRIEVAL SYSTEM READINESS:\")\n",
    "retrieval = readiness_metrics['retrieval_system']\n",
    "print(f\"  Total chunks available: {retrieval['total_chunks']}\")\n",
    "print(f\"  High-quality retrieval chunks: {retrieval['high_quality_chunks']}\")\n",
    "print(f\"  Comprehensive content chunks: {retrieval['comprehensive_chunks']}\")\n",
    "print(f\"  Code example chunks: {retrieval['code_example_chunks']}\")\n",
    "print(f\"  Conceptual chunks: {retrieval['conceptual_chunks']}\")\n",
    "print(f\"  Retrieval coverage score: {retrieval['coverage_score']:.1f}%\")\n",
    "\n",
    "print(f\"\\nQUIZ SYSTEM READINESS:\")\n",
    "quiz = readiness_metrics['quiz_system']\n",
    "print(f\"  Quiz-ready chunks: {quiz['total_quiz_chunks']}\")\n",
    "print(f\"  Quiz types covered: {quiz['quiz_types_covered']}/5\")\n",
    "print(f\"  Difficulty levels: {quiz['difficulty_levels']}\")\n",
    "print(f\"  Question generation potential: {quiz['question_generation_potential']} total questions\")\n",
    "print(f\"  Quiz coverage score: {quiz['quiz_coverage_score']:.1f}%\")\n",
    "\n",
    "print(f\"\\nCONTENT QUALITY METRICS:\")\n",
    "quality = readiness_metrics['content_quality']\n",
    "print(f\"  Average tokens per chunk: {quality['avg_tokens_per_chunk']:.0f}\")\n",
    "print(f\"  Average retrieval score: {quality['avg_retrieval_score']:.1f}\")\n",
    "print(f\"  Average quiz score: {quality['avg_quiz_score']:.1f}\")\n",
    "print(f\"  Multi-purpose chunks: {quality['multi_purpose_chunks']}\")\n",
    "print(f\"  PDF utilization efficiency: {quality['utilization_efficiency']:.1f}%\")\n",
    "\n",
    "# Calculate improvement vs original system\n",
    "original_chunks = 13  # From previous system\n",
    "improvement_factor = len(enhanced_chunks) / original_chunks\n",
    "\n",
    "print(f\"\\nIMPROVEMENT ANALYSIS:\")\n",
    "print(f\"  Chunk count improvement: {improvement_factor:.1f}x (85 vs 13)\")\n",
    "print(f\"  Content utilization: 100% vs ~16% (6.25x improvement)\")\n",
    "print(f\"  Quiz generation capability: NEW FEATURE ADDED\")\n",
    "print(f\"  Dual-purpose optimization: FULLY IMPLEMENTED\")\n",
    "\n",
    "print(f\"\\nAdvanced chunk optimization completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ef87513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving optimized dual-purpose system...\n",
      "Enhanced chunks saved to: c:\\Users\\MOHAMMED ZAKEER\\Downloads\\pandas_rag_project\\data\\processed\\enhanced_chunks_complete.pkl\n",
      "Specialized collections saved to: c:\\Users\\MOHAMMED ZAKEER\\Downloads\\pandas_rag_project\\data\\processed\\specialized_collections.pkl\n",
      "Quiz question bank saved to: c:\\Users\\MOHAMMED ZAKEER\\Downloads\\pandas_rag_project\\data\\processed\\quiz_question_bank.pkl\n",
      "System metrics saved to: c:\\Users\\MOHAMMED ZAKEER\\Downloads\\pandas_rag_project\\data\\processed\\system_readiness_metrics.json\n",
      "Comprehensive summary saved to: c:\\Users\\MOHAMMED ZAKEER\\Downloads\\pandas_rag_project\\data\\processed\\comprehensive_system_summary.json\n",
      "\n",
      "COMPREHENSIVE DUAL-PURPOSE SYSTEM COMPLETED!\n",
      "============================================================\n",
      "\n",
      "SYSTEM ACHIEVEMENTS:\n",
      "  MASSIVE SCALE: 85 chunks from 100% PDF content\n",
      "  DUAL PURPOSE: Optimized for retrieval AND quiz generation\n",
      "  QUIZ EXCELLENCE: 84.7% chunks ready for quiz generation\n",
      "  QUESTION DIVERSITY: 5/5 quiz types, 209 question potential\n",
      "  RETRIEVAL QUALITY: 28.2% high-quality retrieval chunks\n",
      "  IMPROVEMENT: 6.5x more chunks, 6.25x better utilization\n",
      "\n",
      "QUIZ SYSTEM CAPABILITIES:\n",
      "  Multiple Choice: 26 chunks\n",
      "  Code Completion: 29 chunks\n",
      "  True/False: 53 chunks\n",
      "  Fill in Blank: 65 chunks\n",
      "  Scenario Based: 36 chunks\n",
      "\n",
      "RETRIEVAL SYSTEM CAPABILITIES:\n",
      "  High-quality retrieval: 24 chunks\n",
      "  Code examples: 40 chunks\n",
      "  Conceptual content: 8 chunks\n",
      "  Comprehensive content: 37 chunks\n",
      "  Reference material: 63 chunks\n",
      "\n",
      "SAVED FILES VERIFICATION:\n",
      "  Enhanced chunks: True (428.6 KB)\n",
      "  Specialized collections: True (416.7 KB)\n",
      "  Quiz question bank: True (422.0 KB)\n",
      "  System metrics: True (0.7 KB)\n",
      "  Comprehensive summary: True (1.0 KB)\n",
      "\n",
      "READY FOR NEXT STAGE:\n",
      "  All optimized chunks prepared and saved\n",
      "  Quiz question bank structured and ready\n",
      "  Specialized collections created for targeted use\n",
      "  System metrics calculated and documented\n",
      "  Dual-purpose optimization fully implemented\n",
      "\n",
      "Next step: Run notebook 04_quiz_content_generation.ipynb\n",
      "Ready to implement comprehensive quiz generation system!\n",
      "\n",
      "SUCCESS: 5/5 files saved successfully\n",
      "Advanced chunking strategy implementation COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "# Save Optimized Dual-Purpose System\n",
    "\n",
    "print(\"Saving optimized dual-purpose system...\")\n",
    "\n",
    "# Save enhanced chunks with all metadata\n",
    "enhanced_chunks_file = PROCESSED_DATA_PATH / 'enhanced_chunks_complete.pkl'\n",
    "with open(enhanced_chunks_file, 'wb') as f:\n",
    "    pickle.dump(enhanced_chunks, f)\n",
    "print(f\"Enhanced chunks saved to: {enhanced_chunks_file}\")\n",
    "\n",
    "# Save specialized collections\n",
    "collections_file = PROCESSED_DATA_PATH / 'specialized_collections.pkl'\n",
    "with open(collections_file, 'wb') as f:\n",
    "    pickle.dump(specialized_collections, f)\n",
    "print(f\"Specialized collections saved to: {collections_file}\")\n",
    "\n",
    "# Save quiz question bank structure\n",
    "quiz_bank_file = PROCESSED_DATA_PATH / 'quiz_question_bank.pkl'\n",
    "with open(quiz_bank_file, 'wb') as f:\n",
    "    pickle.dump(quiz_question_bank, f)\n",
    "print(f\"Quiz question bank saved to: {quiz_bank_file}\")\n",
    "\n",
    "# Save system readiness metrics\n",
    "metrics_file = PROCESSED_DATA_PATH / 'system_readiness_metrics.json'\n",
    "with open(metrics_file, 'w') as f:\n",
    "    json.dump(readiness_metrics, f, indent=2)\n",
    "print(f\"System metrics saved to: {metrics_file}\")\n",
    "\n",
    "# Create comprehensive system summary\n",
    "system_summary = {\n",
    "    'system_overview': {\n",
    "        'total_chunks': len(enhanced_chunks),\n",
    "        'pdf_utilization': 100.0,\n",
    "        'dual_purpose_optimization': True,\n",
    "        'chunk_improvement_factor': 6.5,\n",
    "        'utilization_improvement_factor': 6.25\n",
    "    },\n",
    "    'retrieval_capabilities': {\n",
    "        'high_quality_chunks': len(specialized_collections['high_retrieval']),\n",
    "        'code_example_chunks': len(specialized_collections['code_examples']),\n",
    "        'conceptual_chunks': len(specialized_collections['conceptual']),\n",
    "        'comprehensive_chunks': len(specialized_collections['comprehensive']),\n",
    "        'reference_chunks': len(specialized_collections['reference']),\n",
    "        'avg_retrieval_score': readiness_metrics['content_quality']['avg_retrieval_score']\n",
    "    },\n",
    "    'quiz_capabilities': {\n",
    "        'quiz_ready_chunks': len(specialized_collections['quiz_generation']),\n",
    "        'question_types_covered': 5,\n",
    "        'difficulty_levels_covered': 3,\n",
    "        'total_question_potential': readiness_metrics['quiz_system']['question_generation_potential'],\n",
    "        'quiz_coverage_percentage': readiness_metrics['quiz_system']['quiz_coverage_score'],\n",
    "        'avg_quiz_score': readiness_metrics['content_quality']['avg_quiz_score']\n",
    "    },\n",
    "    'quiz_type_distribution': {\n",
    "        'multiple_choice': len(quiz_question_bank['multiple_choice']['beginner']) + \n",
    "                          len(quiz_question_bank['multiple_choice']['intermediate']) + \n",
    "                          len(quiz_question_bank['multiple_choice']['advanced']),\n",
    "        'code_completion': len(quiz_question_bank['code_completion']['syntax']) + \n",
    "                          len(quiz_question_bank['code_completion']['functions']) + \n",
    "                          len(quiz_question_bank['code_completion']['practical']),\n",
    "        'true_false': len(quiz_question_bank['true_false']['concepts']) + \n",
    "                     len(quiz_question_bank['true_false']['best_practices']) + \n",
    "                     len(quiz_question_bank['true_false']['facts']),\n",
    "        'fill_blank': len(quiz_question_bank['fill_blank']['parameters']) + \n",
    "                     len(quiz_question_bank['fill_blank']['methods']),\n",
    "        'scenario_based': len(quiz_question_bank['scenario_based']['data_analysis']) + \n",
    "                         len(quiz_question_bank['scenario_based']['problem_solving']) + \n",
    "                         len(quiz_question_bank['scenario_based']['real_world'])\n",
    "    },\n",
    "    'quality_metrics': {\n",
    "        'avg_tokens_per_chunk': readiness_metrics['content_quality']['avg_tokens_per_chunk'],\n",
    "        'multi_purpose_chunks': readiness_metrics['content_quality']['multi_purpose_chunks'],\n",
    "        'content_utilization_efficiency': readiness_metrics['content_quality']['utilization_efficiency']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save comprehensive summary\n",
    "summary_file = PROCESSED_DATA_PATH / 'comprehensive_system_summary.json'\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(system_summary, f, indent=2)\n",
    "print(f\"Comprehensive summary saved to: {summary_file}\")\n",
    "\n",
    "# Display final achievement summary\n",
    "print(f\"\\nCOMPREHENSIVE DUAL-PURPOSE SYSTEM COMPLETED!\")\n",
    "print(f\"=\" * 60)\n",
    "\n",
    "print(f\"\\nSYSTEM ACHIEVEMENTS:\")\n",
    "print(f\"  MASSIVE SCALE: 85 chunks from 100% PDF content\")\n",
    "print(f\"  DUAL PURPOSE: Optimized for retrieval AND quiz generation\")\n",
    "print(f\"  QUIZ EXCELLENCE: 84.7% chunks ready for quiz generation\")\n",
    "print(f\"  QUESTION DIVERSITY: 5/5 quiz types, 209 question potential\")\n",
    "print(f\"  RETRIEVAL QUALITY: 28.2% high-quality retrieval chunks\")\n",
    "print(f\"  IMPROVEMENT: 6.5x more chunks, 6.25x better utilization\")\n",
    "\n",
    "print(f\"\\nQUIZ SYSTEM CAPABILITIES:\")\n",
    "print(f\"  Multiple Choice: {system_summary['quiz_type_distribution']['multiple_choice']} chunks\")\n",
    "print(f\"  Code Completion: {system_summary['quiz_type_distribution']['code_completion']} chunks\")\n",
    "print(f\"  True/False: {system_summary['quiz_type_distribution']['true_false']} chunks\")\n",
    "print(f\"  Fill in Blank: {system_summary['quiz_type_distribution']['fill_blank']} chunks\")\n",
    "print(f\"  Scenario Based: {system_summary['quiz_type_distribution']['scenario_based']} chunks\")\n",
    "\n",
    "print(f\"\\nRETRIEVAL SYSTEM CAPABILITIES:\")\n",
    "print(f\"  High-quality retrieval: {system_summary['retrieval_capabilities']['high_quality_chunks']} chunks\")\n",
    "print(f\"  Code examples: {system_summary['retrieval_capabilities']['code_example_chunks']} chunks\")\n",
    "print(f\"  Conceptual content: {system_summary['retrieval_capabilities']['conceptual_chunks']} chunks\")\n",
    "print(f\"  Comprehensive content: {system_summary['retrieval_capabilities']['comprehensive_chunks']} chunks\")\n",
    "print(f\"  Reference material: {system_summary['retrieval_capabilities']['reference_chunks']} chunks\")\n",
    "\n",
    "print(f\"\\nSAVED FILES VERIFICATION:\")\n",
    "files_to_check = [\n",
    "    (enhanced_chunks_file, \"Enhanced chunks\"),\n",
    "    (collections_file, \"Specialized collections\"), \n",
    "    (quiz_bank_file, \"Quiz question bank\"),\n",
    "    (metrics_file, \"System metrics\"),\n",
    "    (summary_file, \"Comprehensive summary\")\n",
    "]\n",
    "\n",
    "for file_path, description in files_to_check:\n",
    "    exists = file_path.exists()\n",
    "    size = file_path.stat().st_size / 1024 if exists else 0\n",
    "    print(f\"  {description}: {exists} ({size:.1f} KB)\")\n",
    "\n",
    "print(f\"\\nREADY FOR NEXT STAGE:\")\n",
    "print(f\"  All optimized chunks prepared and saved\")\n",
    "print(f\"  Quiz question bank structured and ready\")\n",
    "print(f\"  Specialized collections created for targeted use\")\n",
    "print(f\"  System metrics calculated and documented\")\n",
    "print(f\"  Dual-purpose optimization fully implemented\")\n",
    "\n",
    "print(f\"\\nNext step: Run notebook 04_quiz_content_generation.ipynb\")\n",
    "print(f\"Ready to implement comprehensive quiz generation system!\")\n",
    "\n",
    "# Final verification summary\n",
    "total_files_created = sum(1 for file_path, _ in files_to_check if file_path.exists())\n",
    "print(f\"\\nSUCCESS: {total_files_created}/5 files saved successfully\")\n",
    "print(f\"Advanced chunking strategy implementation COMPLETE!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mygame",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
